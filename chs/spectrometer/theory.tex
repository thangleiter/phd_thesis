% mainfile: main.tex
\chapter{Theory of noise estimation}\label{ch:speck:theory}
There exists a multitude of methods for estimating noise properties.
\todo{lay out some others}

If the noisy process $x(t)$\sidenote{
    We discuss only classical noise here, meaning $x(t)$ commutes with itself at all times. For descriptions of and spectroscopy protocols for quantum noise, refer to \citerr{Clerk2010}{Paz-Silva2017}, for example.
}
has Gaussian statistics, meaning that the amplitude at a given frequency follows a normal distribution with some mean $\mu$ and variance $\sigma^2$, it can be fully described by the \gls{psd} $S(\omega)$.\sidenote{
    As we will see below, a further necessary condition for this is that the process $x(t)$ is \emph{wide-sense stationary}, which means that the autocorrelation function $\ev{x(t)^\ast x(t')} = \ev{x(t)^\ast x(t + \tau)}$ with $\tau = t' - t$. That is, it is a function of only the time lag $\tau$ and not the absolute point in time. For simplicity, we therefore set $t\equiv 0$ below.
}\todo{maybe a classical signal processing ref?}
Given the windowed Fourier transform of the process $x(t)$,\sidenote{
    The windowing arises naturally when observing the process $x(t)$ for a finite amount of time $T$ as one would do in an experiment. Mathematicians might at this point argue the integrability of $x(t)$, but as we deal with physical processes and have no shame, we do not.
}
\begin{align}\label{eq:windowed_ft}
    \hat{x}(\omega) = \frac{1}{\sqrt{T}}\int_{-\flatfrac{T}{2}}^{+\flatfrac{T}{2}}\dd{t}\e^{\i\omega t}x(t)
\end{align}
one defines the \gls{psd} as the ensemble average~\cite{Clerk2010}
\begin{align}\label{eq:psd:definition}
    S(\omega) = \lim_{T\rightarrow\infty}\ev{\hat{x}(\omega)^\ast\hat{x}(\omega)}.
\end{align}
Using \cref{eq:windowed_ft}, the argument of the limit in \cref{eq:psd:definition} becomes
\begin{align}\label{eq:wiener_khinchin_theorem}
    S(\omega) &= \lim_{T\rightarrow\infty}\frac{1}{T}\int_0^T\dd{t}\int_0^T\dd{t'}\e^{\i\omega(t'-t)}\ev{x(t)^\ast x(t')} \\
              &= \lim_{T\rightarrow\infty}\frac{1}{T}\int_0^T\dd{t}\int_{-t}^{T - t}\dd{\tau}\e^{\i\omega\tau}\ev{x(t)^\ast x(t + \tau)} \\
              &= \lim_{T\rightarrow\infty}\frac{1}{T}\int_0^T\dd{t}\int_{-t}^{T - t}\dd{\tau}\e^{\i\omega\tau}\ev{x(t - \flatfrac{\tau}{2})^\ast x(t + \flatfrac{\tau}{2})}.
\end{align}
%    S(\omega) = \int\dd{\tau}\e^{\i\omega\tau}\ev{x(t)^\ast x(t')}
If the observation time $T$ is much longer than the characteristic correlation time $\tau_\mr{c}$ of $x(t)$ over which the auto-correlation function $\ev{x(0)x(\tau)}$ decays,

For the purpose of noise estimation, the assumption of Gaussianity is a rather weak one as the noise typically arises from a large ensemble of individual fluctuators and is therefore well approximated by a Gaussian distribution by the central limit theorem.\sidenote{
    As an example, consider electronic devices, where voltage noise arises from a large number of defects and other charge traps in oxides being populated and depopulated at certain rates $\gamma$. The ensemble average over these so-called \glspl{tlf} then yields the well-known \oneoverf-like noise spectra.
}
Even if the process $x(t)$ is not perfectly Gaussian, non-Gaussian contributions can be seed as higher-order contributions if viewed from the perspective of perturbation theory, and therefore the \gls{psd} still captures a large part of the statistical properties.
For this reason, the \gls{psd} is the central quantity of interest in noise spectroscopy and I will discuss some of its properties in the following.

For real signals $x(t) \in\mathbb{R}$, $S(\omega)$ is an even function and one therefore distinguishes the \emph{two-sided} \gls{psd} $S^{(2)}(\omega)$ from the \emph{one-sided} \gls{psd} $S^{(1)}(\omega) = 2 S^{(2)}(\omega)$ defined only over $\mathbb{R}^+$.
Complex signals $x(t)\in\mathbb{C}$ such as those generated by Lock-in amplifiers after demodulation in turn have an even real and an odd imaginary part.
\todo{for,for,for}